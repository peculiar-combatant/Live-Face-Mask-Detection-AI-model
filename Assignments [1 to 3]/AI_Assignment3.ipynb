{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **AI Assignment 3**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Build an ANN model for Drug classification. 5th June, 2023\n",
        "                                                              \n",
        "\n",
        "> Ananya Singh(20MIC0095) \n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4QsDKWFApJo6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Task:**\n",
        "# **Build a CNN model for Bird species** \n",
        "\n",
        "Bird species classification is the process of using machine learning and computer vision techniques to identify and categorize different species of birds based \n",
        "on their visual characteristics. By analyzing images of birds, models can extract features and patterns to accurately classify bird species. This classification is \n",
        "vital for ecological research, wildlife monitoring, and conservation efforts. Advancements in deep learning and the availability of large annotated datasets have \n",
        "improved the accuracy of bird species classification models. Challenges include variations in lighting, pose, and background clutter. Ongoing research \n",
        "focuses on methods like transfer learning and data augmentation to enhance classification performance and contribute to avian biodiversity understanding \n",
        "and conservation.\n"
      ],
      "metadata": {
        "id": "89PNibAepVTD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\n",
        "\n",
        "# Load the dataset \n",
        "train_dir = 'train/' \n",
        "validation_dir = 'validation/'\n",
        "\n",
        "# Data augmentation \n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   rotation_range=40,\n",
        "                                   width_shift_range=0.2,\n",
        "                                   height_shift_range=0.2,\n",
        "                                   shear_range=0.2,\n",
        "                                   zoom_range=0.2,\n",
        "                                   horizontal_flip=True)\n",
        "\n",
        "# Model architecture\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3,3), input_shape=(150, 150, 3))) \n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(64, (3,3)))\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(128, (3,3)))  \n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(5, activation='softmax')) \n",
        "\n",
        "# Compile model  \n",
        "model.compile(loss='categorical_crossentropy', \n",
        "              optimizer='adam', \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model  \n",
        "model.fit_generator(train_datagen.flow_from_directory(train_dir,\n",
        "                                                    target_size=(150, 150), \n",
        "                                                    batch_size=20, \n",
        "                                                    class_mode='categorical'),\n",
        "                    steps_per_epoch=2000,  \n",
        "                    epochs=15,  \n",
        "                    validation_data=train_datagen.flow_from_directory(validation_dir, \n",
        "                                                                    target_size=(150, 150),\n",
        "                                                                    batch_size=20,\n",
        "                                                                    class_mode='categorical'),\n",
        "                    validation_steps=800) \n",
        "\n",
        "# Evaluate model accuracy on test set\n",
        "test_generator = test_datagen.flow_from_directory(test_dir, \n",
        "                                                 target_size=(150, 150), \n",
        "                                                 batch_size=20, \n",
        "                                                 class_mode='categorical')\n",
        "test_loss, test_acc = model.evaluate_generator(test_generator, steps=50)\n",
        "print('Test accuracy:', test_acc)\n",
        "\n",
        "# Save model \n",
        "model.save('bird_species.h5')\n",
        "\n",
        "# Make predictions on new images\n",
        "test_image = image.load_img('path/to/new/image.jpg', target_size=(150, 150))\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis=0)\n",
        "result = model.predict(test_image)\n",
        "print(result)\n",
        "# result is a list of lists, one list for each image \n",
        "# Each sublist is a prediction vector for the image \n",
        "# The index with the highest value is the predicted class\n"
      ],
      "metadata": {
        "id": "e9F3np7ap7C7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step-1 Get the Dataset from:\"https://www.kaggle.com/datasets/akash2907/bird-species-classification\" "
      ],
      "metadata": {
        "id": "sU1BZ02I3Cnf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#upload the dataset on collab"
      ],
      "metadata": {
        "id": "d5kCnPNj3eT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step-2 Import the libraries"
      ],
      "metadata": {
        "id": "r0cS2rI03IGZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\n"
      ],
      "metadata": {
        "id": "SRDUwosL3LtL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step-3 Load the testing and training dataset"
      ],
      "metadata": {
        "id": "K7xEMoS13Mek"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset \n",
        "data = pd.read_csv('/content/drug_classification.csv')\n",
        "train_dir = 'train/' \n",
        "validation_dir = 'validation/'"
      ],
      "metadata": {
        "id": "41FJsdlw3lWX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step-4 Define the CNN Model"
      ],
      "metadata": {
        "id": "2s-D9eQ83mz7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data augmentation \n",
        "train_datagen = ImageDataGenerator(rescale=1./255,rotation_range=40,width_shift_range=0.2,height_shift_range=0.2,shear_range=0.2, zoom_range=0.2,horizontal_flip=True)\n",
        "\n",
        "# Model architecture\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3,3), input_shape=(150, 150, 3))) \n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(64, (3,3)))\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(128, (3,3)))  \n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(5, activation='softmax')) "
      ],
      "metadata": {
        "id": "mR5M_PYk3sDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step-5 Compile the model"
      ],
      "metadata": {
        "id": "ejqAAHKi33PZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile model  \n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam',  metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "dTl8c-7-38zT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step-6 Training the model"
      ],
      "metadata": {
        "id": "tLv17qLS4F3C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model  \n",
        "model.fit_generator(train_datagen.flow_from_directory(train_dir,target_size=(150, 150), batch_size=20,class_mode='categorical'),steps_per_epoch=2000,  epochs=15,\n",
        "                    validation_data=train_datagen.flow_from_directory(validation_dir,target_size=(150, 150), batch_size=20,class_mode='categorical'),validation_steps=800) \n"
      ],
      "metadata": {
        "id": "6FWC9mBI4Lai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step-7 Evaluate the performance"
      ],
      "metadata": {
        "id": "y16vAihs4gV3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model accuracy on test set\n",
        "test_generator = test_datagen.flow_from_directory(test_dir, \n",
        "                                                 target_size=(150, 150), \n",
        "                                                 batch_size=20, \n",
        "                                                 class_mode='categorical')\n",
        "test_loss, test_acc = model.evaluate_generator(test_generator, steps=50)\n",
        "print('Test accuracy:', test_acc)\n"
      ],
      "metadata": {
        "id": "uUeveIio4r5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step-8 Save the model"
      ],
      "metadata": {
        "id": "KCAUNKj24sLv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model \n",
        "model.save('bird_species.h5')"
      ],
      "metadata": {
        "id": "sD3Vyf774xb6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step-9 Making Predictions"
      ],
      "metadata": {
        "id": "gWh4rbwC4xsp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on new images\n",
        "test_image = image.load_img('path/to/new/image.jpg', target_size=(150, 150))\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis=0)\n",
        "result = model.predict(test_image)\n",
        "print(result)\n",
        "# result is a list of lists, one list for each image \n",
        "# Each sublist is a prediction vector for the image \n",
        "# The index with the highest value is the predicted class"
      ],
      "metadata": {
        "id": "ZQfqR4eR405R"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}